{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4417b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71049202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce6e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5cf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key=\"AIzaSyDGf9gyCmw3dKLzg49DIpIu-mMJN9AyGYQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a78c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/chat-bison-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Chat Bison',\n",
       "       description='Chat-optimized generative language model.',\n",
       "       input_token_limit=4096,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
       "       temperature=0.25,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/text-bison-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Text Bison',\n",
       "       description='Model targeted for text generation.',\n",
       "       input_token_limit=8196,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
       "       temperature=0.7,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/embedding-gecko-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding Gecko',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=1024,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
       "       temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(palm.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1acc2d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode name:models/chat-bison-001\n",
      "model.description:Chat-optimized generative language model.\n",
      "model.supported_generation_methods:['generateMessage', 'countMessageTokens']\n",
      "mode name:models/text-bison-001\n",
      "model.description:Model targeted for text generation.\n",
      "model.supported_generation_methods:['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "mode name:models/embedding-gecko-001\n",
      "model.description:Obtain a distributed representation of a text.\n",
      "model.supported_generation_methods:['embedText', 'countTextTokens']\n"
     ]
    }
   ],
   "source": [
    "for model in palm.list_models():\n",
    "    print(f\"mode name:{model.name}\")\n",
    "    print(f\"model.description:{model.description}\")\n",
    "    print(f\"model.supported_generation_methods:{model.supported_generation_methods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e926b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bison=\"models/text-bison-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38c31dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in text.split() if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "\n",
    "    # Remove newlines\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Remove leading and trailing whitespaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e96bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_summary(text):\n",
    "    prompt=f\"\"\" Your task is to give important point for the text.\n",
    "    I'll give you text.\n",
    "    Your task is to create summary for the text in 200 words.\n",
    "    text is shared below,delimited with triple backticks\n",
    "    \n",
    "    ```\n",
    "    {text}\n",
    "    \n",
    "    ```\n",
    "    \"\"\"\n",
    "    response=palm.generate_text(model=model_bison,\n",
    "    prompt=prompt,temperature=0)\n",
    "    return response.result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e8b3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"My name is Divyasnhu i have been working in domain of Ml, i was national javbelin threower \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22fa7d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name divyasnhu working domain ml national javbelin threower\n"
     ]
    }
   ],
   "source": [
    "new_text=preprocess_text(text)\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c861fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Divyasnhu is a national javelin thrower.\n",
      "- Divyasnhu has been working in the domain of ML.\n"
     ]
    }
   ],
   "source": [
    "print(Generate_summary(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loader.csv_loader import CSVLoader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
